version: '3.8'

services:
  # ----------------------------------------
  # 1. SERVIDOR MLFLOW (TRACKING Y REGISTRY)
  # ----------------------------------------
  mlflow_db:
    image: postgres:15-alpine
    container_name: mlflow_postgres
    environment:
      POSTGRES_USER: mlflow_user
      POSTGRES_PASSWORD: mlflow_password
      POSTGRES_DB: mlflow_db
    volumes:
      - mlflow_postgres_data:/var/lib/postgresql/data
    networks:
      - ml_network
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure

  mlflow_server:
      image: ubuntu/mlflow:2.1.1_1.0-22.04
      container_name: mlflow_server
        
      command: >
        mlflow server
        --backend-store-uri postgresql://mlflow_user:mlflow_password@mlflow_db:5432/mlflow_db
        --default-artifact-root /mlflow_artifacts
        --host 0.0.0.0
        --allowed-hosts "*"
      
      ports:
        - "5000:5000"
        
      environment:
        MLFLOW_TRACKING_URI: http://mlflow_server:5000
        
      volumes:
        - mlflow_artifacts:/mlflow_artifacts
        
      depends_on:
        - mlflow_db
      networks:
        - ml_network
      deploy:
        replicas: 1
        restart_policy:
          condition: on-failure

    # ----------------------------------------
    # 2. MODELO ML (Sklearn/Wine Quality)
    # ----------------------------------------
  sklearn_model:
    image: infra-sklearn_model:latest # Imagen del backend ML
    container_name: sklearn_model
    build:
      context: ../sklearn_model
      dockerfile: Dockerfile
    environment:
      MLFLOW_TRACKING_URI: http://mlflow_server:5000
      MLFLOW_MODEL_URI: models:/whitewine_random_forest_model/latest
    networks:
      - ml_network
    deploy:
      replicas: 2 # Alta disponibilidad y escalabilidad
      update_config:
        parallelism: 1
        delay: 10s
      restart_policy:
        condition: on-failure

    # ----------------------------------------
    # 3. MODELO CNN (Clasificación de Imágenes)
    # ----------------------------------------
  cnn_image:
    image: infra-cnn_image:latest
    container_name: cnn_image
    build:
      context: ../cnn_image
      dockerfile: Dockerfile
    environment:
      MLFLOW_TRACKING_URI: http://mlflow_server:5000
      HF_TOKEN: ${HF_TOKEN}
    networks:
      - ml_network
    deploy:
      replicas: 2
      update_config:
        parallelism: 1
        delay: 10s
      resources:
        limits:
          memory: 2048M
        reservations:
          memory: 512M
      restart_policy:
        condition: on-failure

  # ----------------------------------------
  # 4. LLM CONNECTOR (El Agente/Backend)
  # ----------------------------------------
  llm_connector:
    image: infra-llm_connector:latest # Imagen del backend LLM
    container_name: llm_connector
    build:
      context: ../llm_connector
      dockerfile: Dockerfile
    environment:
      # URLs de APIs internas (usa los nombres de servicio)
      ML_API_URL: http://sklearn_model:8000
      CNN_API_URL: http://cnn_image:8000
      # Tu clave de API (debe ser pasada de forma segura)
      GEMINI_API_KEY: ${GEMINI_API_KEY} 
    networks:
      - ml_network
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
      
  # ----------------------------------------
  # 5. FRONTEND (Gradio UI)
  # ----------------------------------------
  gradio_frontend:
    image: infra-gradio_frontend:latest # Imagen del frontend
    container_name: gradio_frontend
    build:
      context: ../gradio_frontend
      dockerfile: Dockerfile
    environment:
      # URL de la API del LLM Connector
      LLM_API_URL: http://llm_connector:8000
    ports:
      - "80:7860" # Publica el puerto 7860 de Gradio en el puerto 80 del host
    networks:
      - ml_network
    # IMPORTANTE: Asegúrate de que el puerto 7860 esté expuesto en el Dockerfile de Gradio
    deploy:
      replicas: 1
      placement:
        constraints: [node.role == manager] # Para asegurar que siempre esté accesible
      restart_policy:
        condition: on-failure

  # ----------------------------------------
  # VOLÚMENES Y REDES
  # ----------------------------------------
volumes:
  mlflow_postgres_data:
    driver: local
  mlflow_artifacts:
    driver: local

networks:
  ml_network:
    driver: overlay # Crucial para la comunicación entre servicios en diferentes nodos